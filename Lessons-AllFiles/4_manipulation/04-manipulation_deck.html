<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Module 3: R</title>
    <meta charset="utf-8" />
    <meta name="author" content="Instructor: Anjali Silva, PhD" />
    <meta name="date" content="2022-01-01" />
    <script src="libs/header-attrs-2.16/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Module 3: R
]
.subtitle[
## Manipulation
]
.author[
### Instructor: Anjali Silva, PhD
]
.institute[
### Data Sciences Institute, University of Toronto
]
.date[
### 2022
]

---






# Course Documents
* Visit: https://github.com/anjalisilva/IntroductionToR 

* All course material will be available via IntroductionToR GitHub repository (https://github.com/anjalisilva/IntroductionToR). Folder structure is as follows:
   * Lessons - All files: This folder contains all files.
   * **Lessons - Data only**: This folder contains data only.
   * **Lessons - Lesson Plans only**: This folder contains lesson plans only.
   * **Lessons - PDF only**: This folder contains slide PDFs only.
   * README - README file
   * .gitignore - Files to ignore specified by instructor

## Course Contacts
* Instructor: Anjali Silva
  Email: a.silva@utoronto.ca (Must use the subject line DSI-IntroR.   E.g., DSI-IntroR: Inquiry about Lecture I.)

* TA: see GitHub

---

# Overview

- Filtering (Wickham and Grolemund, 2017 Chapter 5, Timbers et al. 2021, Chapter 3.6) 
- Arranging (Wickham and Grolemund, 2017 Chapter 5)
- Selecting (Wickham and Grolemund, 2017 Chapter 5, Timbers et al. 2021, Chapter 3.5)
- The pipe (Wickham and Grolemund, 2017 Chapter 5 &amp; 18; Timbers et al. 2021, Chapter 3.8)
- Mutating (Wickham and Grolemund, 2017 Chapter 5, Timbers et al. 2021, Chapter 3.7, 3.10)
- Summarising (Wickham and Grolemund, 2017 Chapter 5, Timbers et al. 2021, Chapter 3.9)
- Grouping (Wickham and Grolemund, 2017 Chapter 5)
- Cleaning (Alexander, 2022, Chapter 11)


---
# Take a look



```r
glimpse(ads_data)
```

```
## Rows: 1,460
## Columns: 52
## $ StartDate             &lt;dttm&gt; 2019-06-14 09:43:20,…
## $ EndDate               &lt;dttm&gt; 2019-06-14 09:44:30,…
## $ Status                &lt;dbl+lbl&gt; 0, 0, 0, 0, 0, 0,…
## $ Progress              &lt;dbl&gt; 100, 100, 100, 100, 1…
## $ Duration__in_seconds_ &lt;dbl&gt; 70, 105, 88, 109, 109…
## $ Finished              &lt;dbl+lbl&gt; 1, 1, 1, 1, 1, 1,…
## $ RecordedDate          &lt;dttm&gt; 2019-06-14 09:44:31,…
## $ ResponseId            &lt;chr&gt; "R_11dq3s9btLX57LD", …
## $ DistributionChannel   &lt;chr&gt; "anonymous", "anonymo…
## $ UserLanguage          &lt;chr&gt; "EN", "EN", "EN", "EN…
## $ Consent               &lt;dbl+lbl&gt; 1, 1, 1, 1, 1, 1,…
## $ Pol_7                 &lt;dbl+lbl&gt; 5, 3, 1, 2, 6, 4,…
## $ W2_Knowledge          &lt;dbl+lbl&gt; 2, 2, 4, 1, 3, 2,…
## $ Gender                &lt;dbl+lbl&gt; 2, 1, 2, 1, 1, 1,…
## $ Race                  &lt;dbl+lbl&gt; 1, 1, 1, 1, 1, 3,…
## $ W1_Feeling_1          &lt;dbl&gt; 2, 1, 4, 3, 3, 3, 6, …
## $ W1_Actions_1_1        &lt;dbl+lbl&gt; NA, NA, NA, NA, N…
## $ W1_Actions_1_2        &lt;dbl+lbl&gt;  1, NA, NA,  1, N…
## $ W1_Actions_1_3        &lt;dbl+lbl&gt; NA, NA,  1, NA, N…
## $ W1_Actions_1_4        &lt;dbl+lbl&gt;  1,  1, NA,  1, N…
## $ W1_Actions_1_5        &lt;dbl+lbl&gt; NA, NA, NA, NA,  …
## $ W1_Actions_1_6        &lt;dbl+lbl&gt; NA, NA, NA,  1, N…
## $ W1_Actions_1_7        &lt;dbl+lbl&gt; NA, NA, NA, NA, N…
## $ W1_Actions_1_8        &lt;dbl+lbl&gt; NA, NA, NA, NA, N…
## $ W1_Actions_2_1        &lt;dbl+lbl&gt; NA, NA, NA, NA, N…
## $ W1_Actions_2_2        &lt;dbl+lbl&gt;  1,  1, NA, NA, N…
## $ W1_Actions_2_3        &lt;dbl+lbl&gt; NA, NA, NA,  1,  …
## $ W1_Actions_2_4        &lt;dbl+lbl&gt; NA, NA, NA, NA, N…
## $ W1_Actions_2_5        &lt;dbl+lbl&gt; NA, NA,  1,  1, N…
## $ W1_Actions_2_6        &lt;dbl+lbl&gt; NA, NA, NA, NA, N…
## $ W1_Actions_2_7        &lt;dbl+lbl&gt; NA, NA, NA, NA, N…
## $ W2_Feeling_1          &lt;dbl&gt; 5, 5, -2, -2, 3, 3, 0…
## $ W2_Trust_1            &lt;dbl&gt; 3, 1, 4, 2, 3, -5, 5,…
## $ W2_Quality_1          &lt;dbl&gt; -2, 4, 5, 3, 6, 2, -2…
## $ W2_Impact             &lt;dbl+lbl&gt; 4, 3, 6, 5, 6, 6,…
## $ W2_Petition           &lt;dbl+lbl&gt; 4, 5, 3, 5, 3, 3,…
## $ W2_Meeting            &lt;dbl+lbl&gt;  4,  5,  5,  3,  …
## $ Educ                  &lt;dbl+lbl&gt; 4, 5, 5, 5, 5, 3,…
## $ Birthyear             &lt;dbl&gt; 1993, 1978, 1993, 198…
## $ Home_Region           &lt;dbl+lbl&gt; 2, 3, 2, 2, 1, 2,…
## $ Marital_Status        &lt;dbl+lbl&gt; 5, 5, 1, 5, 1, 4,…
## $ Income                &lt;dbl+lbl&gt; 5, 5, 9, 2, 4, 4,…
## $ Employment_Status     &lt;dbl+lbl&gt; 1, 1, 1, 1, 3, 4,…
## $ Q96                   &lt;dbl+lbl&gt; 3, 1, 1, 1, 2, 3,…
## $ Industry              &lt;dbl+lbl&gt;  5,  5, 13, 14,  …
## $ Work_Region           &lt;dbl+lbl&gt;  2,  3,  2,  2,  …
## $ Attention_Sincere     &lt;dbl+lbl&gt; 1, 1, 4, 1, 2, 3,…
## $ Attention_Honest      &lt;dbl+lbl&gt; 5, 5, 4, 5, 4, 2,…
## $ mTurk                 &lt;chr&gt; "5964572", "1281132",…
## $ Block_ID              &lt;chr&gt; "W Con Female", "W Li…
## $ Wing_Order            &lt;chr&gt; "W1", "W1", "W2", "W2…
## $ Vignette              &lt;chr&gt; "W2_Courts_Control", …
```

---

# Filtering

Filtering allows us to select rows based on specific traits


```r
filter(ads_data, Duration__in_seconds_ &lt; 100)
```

```
## # A tibble: 41 × 52
##    StartDate           EndDate             Status    
##    &lt;dttm&gt;              &lt;dttm&gt;              &lt;dbl+lbl&gt; 
##  1 2019-06-14 09:43:20 2019-06-14 09:44:30 0 [IP Add…
##  2 2019-06-14 09:43:29 2019-06-14 09:44:58 0 [IP Add…
##  3 2019-06-14 09:44:00 2019-06-14 09:45:11 0 [IP Add…
##  4 2019-06-14 09:43:32 2019-06-14 09:45:12 0 [IP Add…
##  5 2019-06-14 09:43:48 2019-06-14 09:45:25 0 [IP Add…
##  6 2019-06-14 09:44:24 2019-06-14 09:45:26 0 [IP Add…
##  7 2019-06-14 09:43:50 2019-06-14 09:45:29 0 [IP Add…
##  8 2019-06-14 09:44:15 2019-06-14 09:45:42 0 [IP Add…
##  9 2019-06-14 09:44:30 2019-06-14 09:45:58 0 [IP Add…
## 10 2019-06-14 09:44:36 2019-06-14 09:46:05 0 [IP Add…
## # … with 31 more rows, and 49 more variables:
## #   Progress &lt;dbl&gt;, Duration__in_seconds_ &lt;dbl&gt;,
## #   Finished &lt;dbl+lbl&gt;, RecordedDate &lt;dttm&gt;,
## #   ResponseId &lt;chr&gt;, DistributionChannel &lt;chr&gt;,
## #   UserLanguage &lt;chr&gt;, Consent &lt;dbl+lbl&gt;,
## #   Pol_7 &lt;dbl+lbl&gt;, W2_Knowledge &lt;dbl+lbl&gt;,
## #   Gender &lt;dbl+lbl&gt;, Race &lt;dbl+lbl&gt;, …
```

---

# Arranging

Arranging allows us to sort the order of the table by a certain column


```r
arrange(ads_data, Duration__in_seconds_)
```

```
## # A tibble: 1,460 × 52
##    StartDate           EndDate             Status    
##    &lt;dttm&gt;              &lt;dttm&gt;              &lt;dbl+lbl&gt; 
##  1 2019-06-14 09:58:11 2019-06-14 09:59:01 0 [IP Add…
##  2 2019-06-14 09:44:24 2019-06-14 09:45:26 0 [IP Add…
##  3 2019-06-14 09:43:20 2019-06-14 09:44:30 0 [IP Add…
##  4 2019-06-14 09:44:00 2019-06-14 09:45:11 0 [IP Add…
##  5 2019-06-14 09:52:10 2019-06-14 09:53:26 0 [IP Add…
##  6 2019-06-14 09:45:57 2019-06-14 09:47:13 0 [IP Add…
##  7 2019-06-14 09:50:37 2019-06-14 09:51:53 0 [IP Add…
##  8 2019-06-14 09:45:49 2019-06-14 09:47:08 0 [IP Add…
##  9 2019-06-14 10:10:25 2019-06-14 10:11:45 0 [IP Add…
## 10 2019-06-14 09:53:33 2019-06-14 09:54:54 0 [IP Add…
## # … with 1,450 more rows, and 49 more variables:
## #   Progress &lt;dbl&gt;, Duration__in_seconds_ &lt;dbl&gt;,
## #   Finished &lt;dbl+lbl&gt;, RecordedDate &lt;dttm&gt;,
## #   ResponseId &lt;chr&gt;, DistributionChannel &lt;chr&gt;,
## #   UserLanguage &lt;chr&gt;, Consent &lt;dbl+lbl&gt;,
## #   Pol_7 &lt;dbl+lbl&gt;, W2_Knowledge &lt;dbl+lbl&gt;,
## #   Gender &lt;dbl+lbl&gt;, Race &lt;dbl+lbl&gt;, …
```

---

# Selecting

Selecting allows us to pick certain columns


```r
select(ads_data, RecordedDate)
```

```
## # A tibble: 1,460 × 1
##    RecordedDate       
##    &lt;dttm&gt;             
##  1 2019-06-14 09:44:31
##  2 2019-06-14 09:44:58
##  3 2019-06-14 09:44:59
##  4 2019-06-14 09:45:00
##  5 2019-06-14 09:45:01
##  6 2019-06-14 09:45:12
##  7 2019-06-14 09:45:12
##  8 2019-06-14 09:45:13
##  9 2019-06-14 09:45:13
## 10 2019-06-14 09:45:16
## # … with 1,450 more rows
```

---
# Selecting

We can also remove columns


```r
select(ads_data, -Consent, -DistributionChannel)
```

```
## # A tibble: 1,460 × 50
##    StartDate           EndDate             Status    
##    &lt;dttm&gt;              &lt;dttm&gt;              &lt;dbl+lbl&gt; 
##  1 2019-06-14 09:43:20 2019-06-14 09:44:30 0 [IP Add…
##  2 2019-06-14 09:43:11 2019-06-14 09:44:57 0 [IP Add…
##  3 2019-06-14 09:43:29 2019-06-14 09:44:58 0 [IP Add…
##  4 2019-06-14 09:43:10 2019-06-14 09:45:00 0 [IP Add…
##  5 2019-06-14 09:43:11 2019-06-14 09:45:00 0 [IP Add…
##  6 2019-06-14 09:44:00 2019-06-14 09:45:11 0 [IP Add…
##  7 2019-06-14 09:43:32 2019-06-14 09:45:12 0 [IP Add…
##  8 2019-06-14 09:43:27 2019-06-14 09:45:12 0 [IP Add…
##  9 2019-06-14 09:43:08 2019-06-14 09:45:13 0 [IP Add…
## 10 2019-06-14 09:43:36 2019-06-14 09:45:16 0 [IP Add…
## # … with 1,450 more rows, and 47 more variables:
## #   Progress &lt;dbl&gt;, Duration__in_seconds_ &lt;dbl&gt;,
## #   Finished &lt;dbl+lbl&gt;, RecordedDate &lt;dttm&gt;,
## #   ResponseId &lt;chr&gt;, UserLanguage &lt;chr&gt;,
## #   Pol_7 &lt;dbl+lbl&gt;, W2_Knowledge &lt;dbl+lbl&gt;,
## #   Gender &lt;dbl+lbl&gt;, Race &lt;dbl+lbl&gt;,
## #   W1_Feeling_1 &lt;dbl&gt;, W1_Actions_1_1 &lt;dbl+lbl&gt;, …
```


---

# The pipe

So far, we have written our code like this:


```r
filter(ads_data, Duration__in_seconds_ &lt; 100)
```

```
## # A tibble: 41 × 52
##    StartDate           EndDate             Status    
##    &lt;dttm&gt;              &lt;dttm&gt;              &lt;dbl+lbl&gt; 
##  1 2019-06-14 09:43:20 2019-06-14 09:44:30 0 [IP Add…
##  2 2019-06-14 09:43:29 2019-06-14 09:44:58 0 [IP Add…
##  3 2019-06-14 09:44:00 2019-06-14 09:45:11 0 [IP Add…
##  4 2019-06-14 09:43:32 2019-06-14 09:45:12 0 [IP Add…
##  5 2019-06-14 09:43:48 2019-06-14 09:45:25 0 [IP Add…
##  6 2019-06-14 09:44:24 2019-06-14 09:45:26 0 [IP Add…
##  7 2019-06-14 09:43:50 2019-06-14 09:45:29 0 [IP Add…
##  8 2019-06-14 09:44:15 2019-06-14 09:45:42 0 [IP Add…
##  9 2019-06-14 09:44:30 2019-06-14 09:45:58 0 [IP Add…
## 10 2019-06-14 09:44:36 2019-06-14 09:46:05 0 [IP Add…
## # … with 31 more rows, and 49 more variables:
## #   Progress &lt;dbl&gt;, Duration__in_seconds_ &lt;dbl&gt;,
## #   Finished &lt;dbl+lbl&gt;, RecordedDate &lt;dttm&gt;,
## #   ResponseId &lt;chr&gt;, DistributionChannel &lt;chr&gt;,
## #   UserLanguage &lt;chr&gt;, Consent &lt;dbl+lbl&gt;,
## #   Pol_7 &lt;dbl+lbl&gt;, W2_Knowledge &lt;dbl+lbl&gt;,
## #   Gender &lt;dbl+lbl&gt;, Race &lt;dbl+lbl&gt;, …
```

But what if we want to perform multiple operations in one go? 

---
# The pipe

We can use the pipe `%&gt;%`, which passes what we wrote on the previous line into the next function as the first argument:


```r
ads_data %&gt;%
  filter(Duration__in_seconds_ &lt; 100) %&gt;%
  arrange(Duration__in_seconds_) %&gt;%
  select(RecordedDate, Duration__in_seconds_)
```

```
## # A tibble: 41 × 2
##    RecordedDate        Duration__in_seconds_
##    &lt;dttm&gt;                              &lt;dbl&gt;
##  1 2019-06-14 09:59:02                    50
##  2 2019-06-14 09:45:26                    61
##  3 2019-06-14 09:44:31                    70
##  4 2019-06-14 09:45:12                    70
##  5 2019-06-14 09:53:26                    75
##  6 2019-06-14 09:47:13                    76
##  7 2019-06-14 09:51:54                    76
##  8 2019-06-14 09:47:08                    78
##  9 2019-06-14 10:11:46                    79
## 10 2019-06-14 09:54:54                    80
## # … with 31 more rows
```

---
# The pipe


```r
ads_data %&gt;%
  filter(Duration__in_seconds_ &lt; 100) %&gt;%
  arrange(Duration__in_seconds_) %&gt;%
  select(RecordedDate, Duration__in_seconds_)
```

You can think of this like:

- Take the ADS data
- Filter so we only have the rows where the survey duration is less than 100 seconds
- Arrange so we go from lowest duration to highest
- Select only the date recorded and the duration

---

# Mutating

Mutating can be used to create new columns or change existing columns.


```r
ads_data &lt;- ads_data %&gt;%
  mutate(Birthyear_add_day = str_c(Birthyear, "07-01")) %&gt;%
  mutate(Birthyear_add_day = as_datetime(Birthyear_add_day))
```


```
## # A tibble: 1,460 × 3
##    EndDate             Birthyear Birthyear_add_day  
##    &lt;dttm&gt;                  &lt;dbl&gt; &lt;dttm&gt;             
##  1 2019-06-14 09:44:30      1993 1993-07-01 00:00:00
##  2 2019-06-14 09:44:57      1978 1978-07-01 00:00:00
##  3 2019-06-14 09:44:58      1993 1993-07-01 00:00:00
##  4 2019-06-14 09:45:00      1983 1983-07-01 00:00:00
##  5 2019-06-14 09:45:00      1990 1990-07-01 00:00:00
##  6 2019-06-14 09:45:11      1980 1980-07-01 00:00:00
##  7 2019-06-14 09:45:12      1996 1996-07-01 00:00:00
##  8 2019-06-14 09:45:12      1986 1986-07-01 00:00:00
##  9 2019-06-14 09:45:13      2000 2000-07-01 00:00:00
## 10 2019-06-14 09:45:16      1988 1988-07-01 00:00:00
## # … with 1,450 more rows
```

---
# Mutating


```r
ads_data %&gt;%
  mutate(age = EndDate - Birthyear_add_day) 
```


```
## # A tibble: 1,460 × 4
##    EndDate             Birthyear Birthyear_add_day  
##    &lt;dttm&gt;                  &lt;dbl&gt; &lt;dttm&gt;             
##  1 2019-06-14 09:44:30      1993 1993-07-01 00:00:00
##  2 2019-06-14 09:44:57      1978 1978-07-01 00:00:00
##  3 2019-06-14 09:44:58      1993 1993-07-01 00:00:00
##  4 2019-06-14 09:45:00      1983 1983-07-01 00:00:00
##  5 2019-06-14 09:45:00      1990 1990-07-01 00:00:00
##  6 2019-06-14 09:45:11      1980 1980-07-01 00:00:00
##  7 2019-06-14 09:45:12      1996 1996-07-01 00:00:00
##  8 2019-06-14 09:45:12      1986 1986-07-01 00:00:00
##  9 2019-06-14 09:45:13      2000 2000-07-01 00:00:00
## 10 2019-06-14 09:45:16      1988 1988-07-01 00:00:00
## # … with 1,450 more rows, and 1 more variable:
## #   age &lt;drtn&gt;
```

---

# Summary


```r
summary(ads_data)
```

```
##    StartDate                     
##  Min.   :2019-06-14 09:43:03.00  
##  1st Qu.:2019-06-14 09:46:47.50  
##  Median :2019-06-14 09:52:50.00  
##  Mean   :2019-06-14 09:57:40.11  
##  3rd Qu.:2019-06-14 10:06:28.25  
##  Max.   :2019-06-14 11:19:45.00  
##                                  
##     EndDate                           Status 
##  Min.   :2019-06-14 09:44:30.00   Min.   :0  
##  1st Qu.:2019-06-14 09:51:29.00   1st Qu.:0  
##  Median :2019-06-14 09:57:57.00   Median :0  
##  Mean   :2019-06-14 10:02:23.89   Mean   :0  
##  3rd Qu.:2019-06-14 10:11:19.50   3rd Qu.:0  
##  Max.   :2019-06-14 11:27:10.00   Max.   :0  
##                                              
##     Progress   Duration__in_seconds_    Finished
##  Min.   :100   Min.   :  50.0        Min.   :1  
##  1st Qu.:100   1st Qu.: 178.0        1st Qu.:1  
##  Median :100   Median : 237.0        Median :1  
##  Mean   :100   Mean   : 283.3        Mean   :1  
##  3rd Qu.:100   3rd Qu.: 324.2        3rd Qu.:1  
##  Max.   :100   Max.   :1575.0        Max.   :1  
##                                                 
##   RecordedDate                     ResponseId       
##  Min.   :2019-06-14 09:44:31.00   Length:1460       
##  1st Qu.:2019-06-14 09:51:29.00   Class :character  
##  Median :2019-06-14 09:57:58.00   Mode  :character  
##  Mean   :2019-06-14 10:02:24.49                     
##  3rd Qu.:2019-06-14 10:11:20.50                     
##  Max.   :2019-06-14 11:27:11.00                     
##                                                     
##  DistributionChannel UserLanguage          Consent 
##  Length:1460         Length:1460        Min.   :1  
##  Class :character    Class :character   1st Qu.:1  
##  Mode  :character    Mode  :character   Median :1  
##                                         Mean   :1  
##                                         3rd Qu.:1  
##                                         Max.   :1  
##                                                    
##      Pol_7        W2_Knowledge       Gender     
##  Min.   :1.000   Min.   :1.000   Min.   :1.000  
##  1st Qu.:2.000   1st Qu.:2.000   1st Qu.:1.000  
##  Median :3.000   Median :3.000   Median :1.000  
##  Mean   :3.549   Mean   :2.638   Mean   :1.484  
##  3rd Qu.:5.000   3rd Qu.:3.000   3rd Qu.:2.000  
##  Max.   :7.000   Max.   :4.000   Max.   :3.000  
##                                                 
##       Race       W1_Feeling_1     W1_Actions_1_1
##  Min.   :1.00   Min.   :-10.000   Min.   :1     
##  1st Qu.:1.00   1st Qu.:-10.000   1st Qu.:1     
##  Median :1.00   Median : -7.000   Median :1     
##  Mean   :1.52   Mean   : -5.303   Mean   :1     
##  3rd Qu.:2.00   3rd Qu.: -3.000   3rd Qu.:1     
##  Max.   :6.00   Max.   : 10.000   Max.   :1     
##                                   NA's   :711   
##  W1_Actions_1_2 W1_Actions_1_3 W1_Actions_1_4
##  Min.   :1      Min.   :1      Min.   :1     
##  1st Qu.:1      1st Qu.:1      1st Qu.:1     
##  Median :1      Median :1      Median :1     
##  Mean   :1      Mean   :1      Mean   :1     
##  3rd Qu.:1      3rd Qu.:1      3rd Qu.:1     
##  Max.   :1      Max.   :1      Max.   :1     
##  NA's   :1282   NA's   :839    NA's   :1206  
##  W1_Actions_1_5 W1_Actions_1_6 W1_Actions_1_7
##  Min.   :1      Min.   :1      Min.   :1     
##  1st Qu.:1      1st Qu.:1      1st Qu.:1     
##  Median :1      Median :1      Median :1     
##  Mean   :1      Mean   :1      Mean   :1     
##  3rd Qu.:1      3rd Qu.:1      3rd Qu.:1     
##  Max.   :1      Max.   :1      Max.   :1     
##  NA's   :770    NA's   :1241   NA's   :1246  
##  W1_Actions_1_8 W1_Actions_2_1 W1_Actions_2_2
##  Min.   :1      Min.   :1      Min.   :1     
##  1st Qu.:1      1st Qu.:1      1st Qu.:1     
##  Median :1      Median :1      Median :1     
##  Mean   :1      Mean   :1      Mean   :1     
##  3rd Qu.:1      3rd Qu.:1      3rd Qu.:1     
##  Max.   :1      Max.   :1      Max.   :1     
##  NA's   :1254   NA's   :873    NA's   :1256  
##  W1_Actions_2_3 W1_Actions_2_4 W1_Actions_2_5
##  Min.   :1      Min.   :1      Min.   :1     
##  1st Qu.:1      1st Qu.:1      1st Qu.:1     
##  Median :1      Median :1      Median :1     
##  Mean   :1      Mean   :1      Mean   :1     
##  3rd Qu.:1      3rd Qu.:1      3rd Qu.:1     
##  Max.   :1      Max.   :1      Max.   :1     
##  NA's   :1291   NA's   :1382   NA's   :1140  
##  W1_Actions_2_6 W1_Actions_2_7  W2_Feeling_1    
##  Min.   :1      Min.   :1      Min.   :-10.000  
##  1st Qu.:1      1st Qu.:1      1st Qu.: -5.000  
##  Median :1      Median :1      Median : -1.000  
##  Mean   :1      Mean   :1      Mean   : -1.123  
##  3rd Qu.:1      3rd Qu.:1      3rd Qu.:  3.000  
##  Max.   :1      Max.   :1      Max.   : 10.000  
##  NA's   :1280   NA's   :897                     
##    W2_Trust_1       W2_Quality_1     
##  Min.   :-10.000   Min.   :-10.0000  
##  1st Qu.: -6.000   1st Qu.: -4.2500  
##  Median : -2.000   Median :  0.0000  
##  Mean   : -1.434   Mean   : -0.6719  
##  3rd Qu.:  3.000   3rd Qu.:  3.0000  
##  Max.   : 10.000   Max.   : 10.0000  
##                                      
##    W2_Impact      W2_Petition      W2_Meeting   
##  Min.   :1.000   Min.   :1.000   Min.   :1.000  
##  1st Qu.:3.000   1st Qu.:3.000   1st Qu.:3.000  
##  Median :4.000   Median :4.000   Median :4.000  
##  Mean   :4.047   Mean   :3.869   Mean   :4.208  
##  3rd Qu.:5.000   3rd Qu.:5.000   3rd Qu.:6.000  
##  Max.   :7.000   Max.   :7.000   Max.   :7.000  
##                  NA's   :4       NA's   :3      
##       Educ         Birthyear     Home_Region   
##  Min.   :1.000   Min.   :1941   Min.   :1.000  
##  1st Qu.:3.000   1st Qu.:1974   1st Qu.:2.000  
##  Median :5.000   Median :1984   Median :2.000  
##  Mean   :4.293   Mean   :1981   Mean   :2.271  
##  3rd Qu.:5.000   3rd Qu.:1990   3rd Qu.:3.000  
##  Max.   :8.000   Max.   :2001   Max.   :3.000  
##                                                
##  Marital_Status      Income      Employment_Status
##  Min.   :1.000   Min.   : 1.00   Min.   : 1.000   
##  1st Qu.:1.000   1st Qu.: 4.00   1st Qu.: 1.000   
##  Median :3.000   Median : 6.00   Median : 1.000   
##  Mean   :2.949   Mean   : 6.19   Mean   : 2.324   
##  3rd Qu.:5.000   3rd Qu.: 8.00   3rd Qu.: 3.000   
##  Max.   :5.000   Max.   :12.00   Max.   :10.000   
##                                                   
##       Q96           Industry      Work_Region  
##  Min.   :1.000   Min.   : 1.00   Min.   :1.00  
##  1st Qu.:1.000   1st Qu.: 7.00   1st Qu.:2.00  
##  Median :2.000   Median :11.00   Median :2.00  
##  Mean   :1.836   Mean   :10.78   Mean   :2.21  
##  3rd Qu.:3.000   3rd Qu.:14.00   3rd Qu.:3.00  
##  Max.   :3.000   Max.   :18.00   Max.   :3.00  
##                  NA's   :227     NA's   :227   
##  Attention_Sincere Attention_Honest
##  Min.   :1.000     Min.   :1.000   
##  1st Qu.:1.000     1st Qu.:5.000   
##  Median :1.000     Median :5.000   
##  Mean   :1.464     Mean   :4.869   
##  3rd Qu.:1.000     3rd Qu.:5.000   
##  Max.   :5.000     Max.   :5.000   
##                                    
##     mTurk             Block_ID        
##  Length:1460        Length:1460       
##  Class :character   Class :character  
##  Mode  :character   Mode  :character  
##                                       
##                                       
##                                       
##                                       
##   Wing_Order          Vignette        
##  Length:1460        Length:1460       
##  Class :character   Class :character  
##  Mode  :character   Mode  :character  
##                                       
##                                       
##                                       
##                                       
##  Birthyear_add_day                
##  Min.   :1941-07-01 00:00:00.000  
##  1st Qu.:1974-07-01 00:00:00.000  
##  Median :1984-07-01 00:00:00.000  
##  Mean   :1981-04-21 14:04:16.438  
##  3rd Qu.:1990-07-01 00:00:00.000  
##  Max.   :2001-07-01 00:00:00.000  
## 
```

---

# Pulling a variable for calculations


```r
ads_data %&gt;%
  pull(Duration__in_seconds_)
```

```
##    [1]   70  105   88  109  109   70   99  105  124
##   [10]  100   96  102   61   98  120   86  119  120
##   [19]  143  115  131  164  140  126   88  127  146
##   [28]   88  134  163  111  164  123  176  102  119
##   [37]  187  179  140  144  183  139  123  162  152
##   [46]  184  160  181  163  168  101  190  178  144
##   [55]  194  123  133  135  185  121  163  192  210
##   [64]  167  139  204  117  170  170  199   95  126
##   [73]  208  178  207  146  118  170  110  172  226
##   [82]   78  160  185  186  222  212  185  168  213
##   [91]   76  213  165  173  218  207  214  203  206
##  [100]  213  228  186  240  248  208  176  217  142
##  [109]  190  215  247  163  239  251  185  176  217
##  [118]  193  171  159  239  252  178  168  101  213
##  [127]  227  122  217  225  239  182  178  165  248
##  [136]  190  272  222  101  173  270  121  191  275
##  [145]  210  227  283  188  194  275  236  169  151
##  [154]  295  262  257  234  119  287  276  264  286
##  [163]  193  245  196  289  148  295  208  285  209
##  [172]  318  210  113  193  262  322  168  298  278
##  [181]  216  228  252  185  343  121  319  281  239
##  [190]  115  321  303  304  300  267  190  228  194
##  [199]  271  187  283  232  164  241  213  288  188
##  [208]  323  237  265  245  174  361  172  276  195
##  [217]  357  226  188  223  234  291  197  283  339
##  [226]  100  319  216  224  169  182  257  227  347
##  [235]  284  278  330  237  261  104  216  181  233
##  [244]  195  265  348  193  181  189  246  309  348
##  [253]  192  251  161  366  216  198  133  214  377
##  [262]  174  166  210  158  269   95  289  317  195
##  [271]  125  404  230  176  189  417  281  137  126
##  [280]  321  148  178  298  409  381  168  164  333
##  [289]  119  286  393  146  217  250  205  330  308
##  [298]  396  298  328  223  273  339  284  289  197
##  [307]  360  129  318  270  335  272  424  286  171
##  [316]  429  174  237  323  397  165  194  310  472
##  [325]  211  207  188  371  248  284  195  308  322
##  [334]  137  461  452  260  247  198  292  338  184
##  [343]  262  198  330  189  226  197  212  231  292
##  [352]  205  257  199  333  106  195  360  166  460
##  [361]  306   93  298  427  306  107  390  219  299
##  [370]  260  223  295  491  306  237  138  258  363
##  [379]  228  210  288  230  141  317  276  376  358
##  [388]  202  198  216  113  225   76  168  236  323
##  [397]  160  169  217  176  227  183  167  391  225
##  [406]  191  207  166  223  392  261  361  233  288
##  [415]  252  280  407  152  553  365  263  246  369
##  [424]  122  124  179  177  226  491  465  148  215
##  [433]  461  143  195  165  263  273  263  225  309
##  [442]  122   98  315  478  350  252  519  163  125
##  [451]  146  265  244  360  546  297  122  177  187
##  [460]  226  186  487  303  283  201  212  162  234
##  [469]  603  202  319  412  124  130  158  254  293
##  [478]  160  240  305  210  265  241  493  169  193
##  [487]  287  114   75  190  231  431  411  603  343
##  [496]  522  275  277  462  469  149  155  247  230
##  [505]  326  360  159  184  246  227  409  383  210
##  [514]  394  170  218  143  325  244  200  434  181
##  [523]  226  178  237  226  142  232  106  392  256
##  [532]  101  174  107  215  373  331  177  461  256
##  [541]  202   99   91  490  247  233  433  668  385
##  [550]  253  146  178  268  200  258  356  299  243
##  [559]  161  131  287  340  424  273  272  325  273
##  [568]  238  220  522  459  468  166  157  246   80
##  [577]  193  167  367  193  501  139  290  374  547
##  [586]  294  108  221  273  112  430  633  270  208
##  [595]  485  198  346  224  212  165  233  155  259
##  [604]  245  296  157  266  125  281  249  379  177
##  [613]  193  164  312  165  243  202  298  166  232
##  [622]  234  205  231  583  238  237  207  146  217
##  [631]  678  147  259  653  233  504  142  284  763
##  [640]  216  228  188  289  121  128  241  266  171
##  [649]  273  315  188  215  193  323  225  255  346
##  [658]  207  297  214  216  198  199  342  101  349
##  [667]   81  720  140  132  412  410  219  250  174
##  [676]  395  513  534  260  291  122  298  151  244
##  [685]  250  319  172  430  782  470  286  325  202
##  [694]  633  268  215  609  241  218  318  219  130
##  [703]  252  232  211  248  139  262  277  300  240
##  [712]  282  250  485  256  724  304  261  212  220
##  [721]  431  227  278  207  218  270  176  473  320
##  [730]  379  479  115  224  210  417  197  453  139
##  [739]  738  299  182  152  410  141  384  139  905
##  [748]  332  544  406  316  217  203  164  153  304
##  [757]  243  349  724  233  374  515  442  332  212
##  [766]  589  272  526  337  169  113  522  134  582
##  [775]  316  256  402  384  207   50  138  224  289
##  [784]  401  187  431  316  408  617  137  509  673
##  [793]  169  275  462  286  632  224  181  217  361
##  [802]  409  431  190  699  169  158  685  246  163
##  [811]  135  486  162  400  557  229  162  124  172
##  [820]  281  463  273  194  533  967  222  179   83
##  [829]  287  179  262  233  180  166  683  218  180
##  [838]  132  236  200  308  224  184  177  138  264
##  [847]  252  409  314  199  190  171  177  241  630
##  [856]  264  270  585  234  141  895  438  194  238
##  [865]  732  362  192  109  161  884  231  264  398
##  [874]  567  130  235  604  132  245  170  468  399
##  [883]  119  866  323 1075  223  181   93  422  149
##  [892]  101  307  512  315  343  124  367  317  314
##  [901]  232  505  312  227   91  299  302  468  423
##  [910]  402  868  474  163   96  921  199  245  307
##  [919]  403  432  212 1032  299  592  307   95  188
##  [928]  155   97  197  502  161  413  248  168  125
##  [937]  223  205  198  453  311  209  149  186  239
##  [946]  574  781  667  179  244  391  422  135  293
##  [955]  115  423  992  209  228  158  157  139  322
##  [964]  439  379  328 1090  198  157  203  110  338
##  [973]  155  199  234  214  725  299  325  277  305
##  [982]  243  160  523  311 1200  218  270  154  359
##  [991]  259  256  227  193  346  694  291  122  406
## [1000]  723
##  [ reached getOption("max.print") -- omitted 460 entries ]
## attr(,"label")
## [1] "Duration (in seconds)"
## attr(,"format.spss")
## [1] "F40.2"
## attr(,"display_width")
## [1] 5
```

---

# Using the pulled variable for descriptive statistics

Median


```r
ads_data %&gt;%
  pull(Duration__in_seconds_) %&gt;%
  median(na.rm = TRUE)
```

```
## [1] 237
```

We have to tell the mean() function to disregard NAs by writing `na.rm = TRUE`

---
# Using the pulled variable for descriptive statistics

Mean


```r
ads_data %&gt;%
  pull(Duration__in_seconds_) %&gt;%
  mean(na.rm = TRUE)
```

```
## [1] 283.261
```

---
# Using the pulled variable for descriptive statistics


Range can be calculated using the `range()` function.


```r
ads_data %&gt;%
  pull(Duration__in_seconds_) %&gt;%
  range(na.rm = TRUE)
```

```
## [1]   50 1575
```

Variance can be calculated using the `var()` function.


```r
ads_data %&gt;%
  pull(Duration__in_seconds_) %&gt;%
  var(na.rm = TRUE)
```

```
## [1] 29487.81
```

---
# Using the pulled variable for descriptive statistics

Standard Deviation can be calculated using the `sd()` function.


```r
ads_data %&gt;%
  pull(Duration__in_seconds_) %&gt;%
  sd(na.rm = TRUE)
```

```
## [1] 171.7202
```

---

# Summarise


```r
ads_data %&gt;%
  summarise(mean_time = mean(Duration__in_seconds_, na.rm = TRUE),
            sd_time = sd(Duration__in_seconds_, na.rm = TRUE))
```

```
## # A tibble: 1 × 2
##   mean_time sd_time
##       &lt;dbl&gt;   &lt;dbl&gt;
## 1      283.    172.
```

---

# Grouping

Before summarising, we can group by a categorical variable


```r
ads_data %&gt;%
  group_by(Gender) %&gt;%
  summarise(count = n(),
            mean_time = mean(Duration__in_seconds_, na.rm = TRUE),
            sd_time = sd(Duration__in_seconds_, na.rm = TRUE))
```

```
## # A tibble: 3 × 4
##   Gender                        count mean_…¹ sd_time
##   &lt;dbl+lbl&gt;                     &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;
## 1 1 [Male]                        758    269.   162. 
## 2 2 [Female]                      698    299.   181. 
## 3 3 [Prefer a third option/Oth…     4    229     37.7
## # … with abbreviated variable name ¹​mean_time
```

---

class: inverse, center, middle

# Manipulation application: data cleaning

---
# Data cleaning



Graphing year of birth shows that it goes from 1 to about 80.


```r
ces_2019_raw %&gt;%
  ggplot(aes(x = cps19_yob)) +
  geom_histogram()
```

![](04-manipulation_deck_files/figure-html/unnamed-chunk-25-1.png)&lt;!-- --&gt;

---
# Data cleaning

The codebook says that a value of 1 corresponds to a birth year of 1920, value of 2 to a birth year of 1921, and so on. We can create a new variable that reads more intuitively.


```r
CES_data &lt;- ces_2019_raw %&gt;%
  mutate(cps19_yob_fix = cps19_yob + 1919)
```

---
# Data cleaning


```r
CES_data %&gt;%
  ggplot(aes(x = cps19_yob_fix)) +
  geom_histogram()
```

![](04-manipulation_deck_files/figure-html/unnamed-chunk-27-1.png)&lt;!-- --&gt;

Better!

---

# Add a variable for age

Now that we have an accurate birth year, maybe we would like to have the age of the individual as well.


```r
CES_data &lt;- CES_data %&gt;%
  mutate(age = 2019 - cps19_yob_fix)
```

---

# Add a variable for age


```r
CES_data %&gt;%
  ggplot(aes(x = age)) +
  geom_histogram()
```

![](04-manipulation_deck_files/figure-html/unnamed-chunk-29-1.png)&lt;!-- --&gt;

---

# Recoding the gender variable


```r
CES_data %&gt;%
  ggplot(aes(x = cps19_gender)) + 
  geom_bar()
```

![](04-manipulation_deck_files/figure-html/unnamed-chunk-30-1.png)&lt;!-- --&gt;

---

# Recoding the gender variable


```r
CES_data &lt;- CES_data %&gt;%
  mutate(cps19_gender_fix = factor(cps19_gender)) %&gt;%
  mutate(cps19_gender_fix = fct_recode(cps19_gender_fix,
                                       "M" = "1",
                                       "F" = "2", 
                                       "NB" = "3"))
```

---
# Recoding the gender variable


```r
CES_data %&gt;%
  ggplot(aes(x = cps19_gender_fix)) + 
  geom_bar()
```

![](04-manipulation_deck_files/figure-html/unnamed-chunk-32-1.png)&lt;!-- --&gt;

---

# Fixing household counts


```r
CES_data %&gt;%
  filter(cps19_household &gt; 10) %&gt;%
  arrange(-cps19_household) %&gt;%
  pull(cps19_household)
```

```
##  [1] 7766666   72000   50000   20000   10000    5667
##  [7]    2000     501     321      99      89      87
## [13]      69      54      54      50      44      40
## [19]      34      33      29      27      23      22
## [25]      22      20      20      20      15      15
## [31]      13      13      12      12      12      11
## [37]      11      11      11      11      11      11
## [43]      11
```

---
# Fixing household counts


```r
CES_data &lt;- CES_data %&gt;%
  mutate(cps19_household = ifelse(cps19_household &gt; 15, 
                                  NA, 
                                  cps19_household))

CES_data %&gt;%
  filter(cps19_household &gt; 10) %&gt;%
  pull(cps19_household)
```

```
##  [1] 12 11 15 12 11 13 11 11 11 15 13 12 11 11 11
```

---

# Fixing income


```r
CES_data %&gt;%
  filter(cps19_income_number &gt; 1000000) %&gt;%
  arrange(-cps19_income_number) %&gt;%
  pull(cps19_income_number)
```

```
##  [1] 6.747658e+60 1.000000e+21 1.000000e+15
##  [4] 8.769655e+10 8.889899e+09 3.062936e+09
##  [7] 1.000000e+09 1.000000e+09 6.788765e+08
## [10] 3.000000e+08 7.245600e+07 3.454534e+07
## [13] 3.000000e+07 1.000000e+07 9.999999e+06
## [16] 8.900000e+06 7.696588e+06 7.440000e+06
## [19] 6.848382e+06 6.787145e+06 6.782800e+06
## [22] 6.500100e+06 4.500000e+06 3.000000e+06
## [25] 2.332100e+06 2.000000e+06 2.000000e+06
## [28] 1.872717e+06 1.800000e+06 1.650000e+06
## [31] 1.500000e+06 1.500000e+06 1.450000e+06
## [34] 1.300000e+06 1.290000e+06 1.250000e+06
## [37] 1.250000e+06 1.250000e+06 1.150000e+06
```

---
# Fixing income


```r
CES_data &lt;- CES_data %&gt;%
  mutate(cps19_income_number = ifelse(cps19_income_number &gt;= 1000000000, 
                                  NA, 
                                  cps19_income_number))

CES_data %&gt;%
  filter(cps19_income_number &gt; 1000000) %&gt;%
  pull(cps19_income_number)
```

```
##  [1]   2000000   1500000   4500000   3000000
##  [5]   6848382   7696588   6787145   1250000
##  [9]   1650000   1872717 678876545   1300000
## [13]   1150000   1250000   9999999   1450000
## [17]   1500000   6500100  30000000   8900000
## [21] 300000000   7440000   6782800   2332100
## [25]   1800000   2000000  10000000   1290000
## [29]  72456000  34545345   1250000
```

---

class: inverse, center, middle

# Manipulation application: Summarising data

---
# Summarising data



First we can select only data for Ontario using `filter()`:


```r
CES_data %&gt;%
  filter(cps19_province == "Ontario")
```

```
## # A tibble: 14,160 × 620
##    cps19_StartDate     cps19_EndDate       cps19_Re…¹
##    &lt;dttm&gt;              &lt;dttm&gt;              &lt;chr&gt;     
##  1 2019-09-13 10:01:19 2019-09-13 10:27:29 R_USWDAPc…
##  2 2019-09-13 10:05:37 2019-09-13 10:50:53 R_3IQaeDX…
##  3 2019-09-13 10:05:52 2019-09-13 10:32:53 R_27WeMQ1…
##  4 2019-09-13 10:10:20 2019-09-13 10:29:45 R_3LiGZcC…
##  5 2019-09-13 10:14:47 2019-09-13 10:32:32 R_1Iu8R1U…
##  6 2019-09-13 10:15:39 2019-09-13 10:30:59 R_2EcS26h…
##  7 2019-09-13 10:15:48 2019-09-13 10:37:45 R_3yrt44w…
##  8 2019-09-13 10:16:08 2019-09-13 10:40:14 R_10OBmXJ…
##  9 2019-09-13 10:16:24 2019-09-13 10:41:24 R_2e5nvu0…
## 10 2019-09-13 10:17:06 2019-09-13 10:35:47 R_2OJdv16…
## # … with 14,150 more rows, 617 more variables:
## #   cps19_consent &lt;dbl&gt;, cps19_citizenship &lt;dbl&gt;,
## #   cps19_yob &lt;dbl&gt;, cps19_yob_2001_age &lt;dbl&gt;,
## #   cps19_gender &lt;fct&gt;, cps19_province &lt;fct&gt;,
## #   cps19_education &lt;dbl&gt;, cps19_demsat &lt;dbl&gt;,
## #   cps19_imp_iss &lt;chr&gt;, cps19_imp_iss_party &lt;dbl&gt;,
## #   cps19_imp_iss_party_7_TEXT &lt;chr&gt;, …
```

---
# Summarising data

We don't need to be dealing with all the columns. We can specifically select the ones we want using `select()`:

"How satisfied are you with the performance of your provincial government under ${e://Field/premier}?", "In provincial politics, do you usually think of yourself as a:", and income.


```r
CES_data %&gt;%
  filter(cps19_province == "Ontario") %&gt;%
  select(cps19_prov_gov_sat,
         cps19_prov_id,
         cps19_income_number)
```

```
## # A tibble: 14,160 × 3
##    cps19_prov_gov_sat   cps19_prov_id         cps19…¹
##    &lt;fct&gt;                &lt;fct&gt;                   &lt;dbl&gt;
##  1 Not very satisfied   Liberal                    NA
##  2 Fairly satisfied     Progressive Conserva…      NA
##  3 Fairly satisfied     Liberal                 56000
##  4 Not at all satisfied NDP                        NA
##  5 Not at all satisfied NDP                         0
##  6 Not at all satisfied None                       NA
##  7 Not at all satisfied NDP                        NA
##  8 Not very satisfied   Liberal                    NA
##  9 Not very satisfied   NDP                        NA
## 10 Not at all satisfied Liberal                    NA
## # … with 14,150 more rows, and abbreviated variable
## #   name ¹​cps19_income_number
```

---
# Summarising data
Now that our data looks like what we would like it to, we can start creating a summary table. Since we have the income for each participant, we can look at median incomes. We also want to know how many participants are in each category.

First, we can group the data by provincial political self-ID. To do this, we use `group_by()` to group the data and `summarise()` to produce values for each group we have created. We will start with calculating the `median()` for the incomes. We can add multiple arguments to the `summarise()` argument. `n()` adds a count for each group.

---
# Summarising data

```r
CES_data %&gt;%
  filter(cps19_province == "Ontario") %&gt;%
  select(cps19_prov_gov_sat,
         cps19_prov_id,
         cps19_income_number) %&gt;%
  group_by(cps19_prov_gov_sat) %&gt;%
  summarise(median_income = median(cps19_income_number,
                                   na.rm = TRUE),
            count = n())
```

```
## # A tibble: 5 × 3
##   cps19_prov_gov_sat              median_income count
##   &lt;fct&gt;                                   &lt;dbl&gt; &lt;int&gt;
## 1 Very satisfied                          80000   872
## 2 Fairly satisfied                        80000  2738
## 3 Not very satisfied                      75000  3212
## 4 Not at all satisfied                    72000  6853
## 5 Don't know/prefer not to answer         50000   485
```

---
# Grouping
In our table, the satisfaction ratings are ordered alphabetically. We would like them to be ordered logically. We can do this by ordering the factor variable.


```r
CES_data %&gt;%
  filter(cps19_province == "Ontario") %&gt;%
  select(cps19_prov_gov_sat,
         cps19_prov_id,
         cps19_income_number) %&gt;%
  mutate(cps19_prov_id = factor(cps19_prov_id,
                                     levels = c("Liberal",
                                                "Progressive Conservative",
                                                "NDP",
                                                "Green",
                                                "Another party",
                                                "None",
                                                "Don't know/prefer not to answer")))
```

---
# Grouping


```
## # A tibble: 14,160 × 3
##    cps19_prov_gov_sat   cps19_prov_id         cps19…¹
##    &lt;fct&gt;                &lt;fct&gt;                   &lt;dbl&gt;
##  1 Not very satisfied   Liberal                    NA
##  2 Fairly satisfied     Progressive Conserva…      NA
##  3 Fairly satisfied     Liberal                 56000
##  4 Not at all satisfied NDP                        NA
##  5 Not at all satisfied NDP                         0
##  6 Not at all satisfied None                       NA
##  7 Not at all satisfied NDP                        NA
##  8 Not very satisfied   Liberal                    NA
##  9 Not very satisfied   NDP                        NA
## 10 Not at all satisfied Liberal                    NA
## # … with 14,150 more rows, and abbreviated variable
## #   name ¹​cps19_income_number
```

---
# Grouping
And combine this with our table from before:


```r
CES_data %&gt;%
  filter(cps19_province == "Ontario") %&gt;%
  select(cps19_prov_gov_sat,
         cps19_prov_id,
         cps19_income_number) %&gt;%
  mutate(cps19_prov_gov_sat = factor(cps19_prov_gov_sat,
                                     levels = c("Not at all satisfied",
                                                "Not very satisfied",
                                                "Fairly satisfied",
                                                "Very satisfied",
                                                "Don't know/prefer not to answer"))) %&gt;%
  group_by(cps19_prov_gov_sat) %&gt;%
  summarise(median_income = median(cps19_income_number,
                                   na.rm = TRUE),
            count = n())
```

```
## # A tibble: 5 × 3
##   cps19_prov_gov_sat              median_income count
##   &lt;fct&gt;                                   &lt;dbl&gt; &lt;int&gt;
## 1 Not at all satisfied                    72000  6853
## 2 Not very satisfied                      75000  3212
## 3 Fairly satisfied                        80000  2738
## 4 Very satisfied                          80000   872
## 5 Don't know/prefer not to answer         50000   485
```

---
# Grouping
What happens if we group by political identification instead?


```r
CES_data %&gt;%
  filter(cps19_province == "Ontario") %&gt;%
  select(cps19_prov_gov_sat,
         cps19_prov_id,
         cps19_income_number) %&gt;%
  group_by(cps19_prov_id) %&gt;%
  summarise(median_income = median(cps19_income_number,
                                   na.rm = TRUE),
            count = n())
```

```
## # A tibble: 7 × 3
##   cps19_prov_id                   median_income count
##   &lt;fct&gt;                                   &lt;dbl&gt; &lt;int&gt;
## 1 Liberal                                 80000  4607
## 2 NDP                                     65000  2413
## 3 Green                                   60000   812
## 4 Progressive Conservative                80000  3629
## 5 Another party                           50000    90
## 6 None                                    68000  1367
## 7 Don't know/prefer not to answer         60000  1242
```

---
# Grouping
We could order the parties in a way that makes more sense:


```r
CES_data %&gt;%
  filter(cps19_province == "Ontario") %&gt;%
  select(cps19_prov_gov_sat,
         cps19_prov_id,
         cps19_income_number) %&gt;%
  mutate(cps19_prov_id = factor(cps19_prov_id,
                                     levels = c("Liberal",
                                                "Progressive Conservative",
                                                "NDP",
                                                "Green",
                                                "Another party",
                                                "None",
                                                "Don't know/prefer not to answer"))) %&gt;%
  group_by(cps19_prov_id) %&gt;%
  summarise(median_income = median(cps19_income_number,
                                   na.rm = TRUE),
            count = n())
```

---
# Grouping


```
## # A tibble: 7 × 3
##   cps19_prov_id                   median_income count
##   &lt;fct&gt;                                   &lt;dbl&gt; &lt;int&gt;
## 1 Liberal                                 80000  4607
## 2 Progressive Conservative                80000  3629
## 3 NDP                                     65000  2413
## 4 Green                                   60000   812
## 5 Another party                           50000    90
## 6 None                                    68000  1367
## 7 Don't know/prefer not to answer         60000  1242
```

---
# Grouping
Or we could sort by median income. We can do that using `arrange()`:


```r
CES_data %&gt;%
  filter(cps19_province == "Ontario") %&gt;%
  select(cps19_prov_gov_sat,
         cps19_prov_id,
         cps19_income_number) %&gt;%
  group_by(cps19_prov_id) %&gt;%
  summarise(median_income = median(cps19_income_number,
                                   na.rm = TRUE),
            count = n()) %&gt;%
  arrange(-median_income)
```

```
## # A tibble: 7 × 3
##   cps19_prov_id                   median_income count
##   &lt;fct&gt;                                   &lt;dbl&gt; &lt;int&gt;
## 1 Liberal                                 80000  4607
## 2 Progressive Conservative                80000  3629
## 3 None                                    68000  1367
## 4 NDP                                     65000  2413
## 5 Green                                   60000   812
## 6 Don't know/prefer not to answer         60000  1242
## 7 Another party                           50000    90
```

---
# Grouping
`group_by()` can also have multiple arguments, so we can group by `cps19_prov_gov_sat` and `cps19_prov_id` at the same time:


```r
CES_data %&gt;%
  filter(cps19_province == "Ontario") %&gt;%
  select(cps19_prov_gov_sat,
         cps19_prov_id,
         cps19_income_number) %&gt;%
  mutate(cps19_prov_id = factor(cps19_prov_id,
                                     levels = c("Liberal",
                                                "Progressive Conservative",
                                                "NDP",
                                                "Green",
                                                "Another party",
                                                "None",
                                                "Don't know/prefer not to answer"))) %&gt;%
  mutate(cps19_prov_gov_sat = factor(cps19_prov_gov_sat,
                                     levels = c("Not at all satisfied",
                                                "Not very satisfied",
                                                "Fairly satisfied",
                                                "Very satisfied",
                                                "Don't know/prefer not to answer"))) %&gt;%
  group_by(cps19_prov_gov_sat, cps19_prov_id) %&gt;%
  summarise(median_income = median(cps19_income_number,
                                   na.rm = TRUE))
```

```
## # A tibble: 35 × 3
## # Groups:   cps19_prov_gov_sat [5]
##    cps19_prov_gov_sat   cps19_prov_id         media…¹
##    &lt;fct&gt;                &lt;fct&gt;                   &lt;dbl&gt;
##  1 Not at all satisfied Liberal                 80000
##  2 Not at all satisfied Progressive Conserva…   85000
##  3 Not at all satisfied NDP                     65000
##  4 Not at all satisfied Green                   60000
##  5 Not at all satisfied Another party           40000
##  6 Not at all satisfied None                    62000
##  7 Not at all satisfied Don't know/prefer no…   68500
##  8 Not very satisfied   Liberal                 80000
##  9 Not very satisfied   Progressive Conserva…   78000
## 10 Not very satisfied   NDP                     65000
## # … with 25 more rows, and abbreviated variable name
## #   ¹​median_income
```

---
# Grouping
This table is less easy to read, though. `spread()` can make a table that is wide rather than long. We specify the `key`, the variable that will become our column names, and the `value`, which will become the values in those columns:


```r
CES_data %&gt;%
  filter(cps19_province == "Ontario") %&gt;%
  select(cps19_prov_gov_sat,
         cps19_prov_id,
         cps19_income_number) %&gt;%
  mutate(cps19_prov_id = factor(cps19_prov_id,
                                     levels = c("Liberal",
                                                "Progressive Conservative",
                                                "NDP",
                                                "Green",
                                                "Another party",
                                                "None",
                                                "Don't know/prefer not to answer"))) %&gt;%
  mutate(cps19_prov_gov_sat = factor(cps19_prov_gov_sat,
                                     levels = c("Not at all satisfied",
                                                "Not very satisfied",
                                                "Fairly satisfied",
                                                "Very satisfied",
                                                "Don't know/prefer not to answer"))) %&gt;%
  group_by(cps19_prov_gov_sat, cps19_prov_id) %&gt;%
  summarise(median_income = median(cps19_income_number,
                                   na.rm = TRUE)) %&gt;%
  spread(key = cps19_prov_gov_sat,
         value = median_income)
```


---
# Grouping

```
## # A tibble: 7 × 6
##   cps19_pro…¹ Not a…² Not v…³ Fairl…⁴ Very …⁵ Don't…⁶
##   &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
## 1 Liberal       80000   80000   79999   79876   60000
## 2 Progressiv…   85000   78000   82000   84000   72000
## 3 NDP           65000   65000   76888   80000   37000
## 4 Green         60000   60000   72750   66000   32500
## 5 Another pa…   40000   48500   73500  150000   52000
## 6 None          62000   74000   69000   66000   43000
## 7 Don't know…   68500   59500   70000   85000   50000
## # … with abbreviated variable names ¹​cps19_prov_id,
## #   ²​`Not at all satisfied`, ³​`Not very satisfied`,
## #   ⁴​`Fairly satisfied`, ⁵​`Very satisfied`,
## #   ⁶​`Don't know/prefer not to answer`
```


---

class: inverse, center, middle

# Exercises

---
# Exercises

1. Filter the rows in the CES_data dataset where the survey-taker is between 30 and 50 (cps19_age).
2. Filter the rows in the CES_data dataset where the survey-taker answered the cps19_votechoice question (i.e. the cps19_votechoice variable is not NA).
3. Select the variables cps19_age and cps19_province from the CES_data dataset.
4. Select all variables except cps19_province from the CES_data dataset.

---
# Exercises

1. Create a variable in the dataset CES_data that states if a person consumes news content or not (i.e. cps19_news_cons is equal to "0 minutes" or it is not).
2. Modify the variable cps19_income_number in the dataset CES_data so that it is measured in thousands (i.e. divide the income number by 1000).

---
# Exercises

1. Use the CES_data dataset. Group by cps19_votechoice. Find both the median and mean rating of Trudeau (cps19_lead_rating_23):
2. Use the CES_data dataset. Group by cps19_imm and cps19_spend_educ. Find the count for each group.

---
# Exercises

* 1 - Fix this error:


```r
CES_data %&gt;%
  summarise(mean = mean(cps19_age)) %&gt;%
  group_by(cps19_gender)
```

* 2 - Fix this error:


```r
CES_data %&gt;%
  filter(cps19_vote_choice == "Green Party")
```
---
# Exercises

* 3 - Fix this error:


```r
CES_data %&gt;%
  mutate(cps19_fed_donate = factor(cps19_fed_donate,
                                     levels = c("Yes",
                                                "No",
                                                "Don't know/ Prefer not to answer"))
```

* 4 - Fix this error:


```r
CES_data %&gt;%
  select(cps19_province
         cps19_age
         cps19_gender)
```

---

class: inverse, center, middle

# Any questions?



    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
